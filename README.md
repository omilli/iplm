# Interplanetary Language Models (iplm.js)

Run Large Language Models in a privacy-focused, local-first, peer-to-peer progressive web app with offline support.

### Goals

- Offline
- Decentralized
- Anonymous

### Tech Stack

- Hella
- MLC WebLLM
- PouchDB
- PicoCSS
- Vite 

## LLM Sharding

### Model Sharding

`@mlc-ai/web-llm` compatible models are sharded across the iplm network which is powered by `pouchdb`. Support for partial and parallel model installs comes out of the box. Models are installed directly from peers.

### Prompt Sharding

Large prompts, or prompts that cover multiple subjects, are sharded into multiple prompts, which are run in parallel via web workers.

## Core Functionality

### Client
- ğŸŸ¢ Server Sync
- ğŸ”´ Install model from source
- ğŸ”´ Write model to database
- ğŸ”´ Install model using p2p shards
- ğŸ”´ Write model shards to browser cache
- ğŸ”´ Choose prompt model
- ğŸ”´ Create query intent model
- ğŸ”´ Process & display chat

### Network
- ğŸŸ¢ Model Server Sync
- ğŸŸ¡ Database Services
- ğŸŸ  Model Services
- ğŸ”´ Fetch model from source
- ğŸ”´ Write model files to database 

## Architecture

### Client

ğŸ“¦src    
 â”£ ğŸ“‚services  
 â”£ â”£ ğŸ“‚chat  
 â”£ â”£ ğŸ“‚database
 â”£ â”£ ğŸ“‚model  
 â”£ â”— ğŸ“‚worker  
 â”£ ğŸ“‚ui  
 â”£ â”£ ğŸ“‚components  
 â”£ â”— ğŸ“‚pages  
 â”— ğŸ“‚utils  

### Network

ğŸ“¦src      
 â”£ servers  
 â”£ â”— ğŸ“‚model  
 â”£ ğŸ“‚services  
 â”£ â”£ ğŸ“‚database  
 â”£ â”£ ğŸ“‚models  
 â”— ğŸ“‚utils  

 ## Coding Style
 - Functional programming
 - Prefix functions with verbs
 - Only 1 function export per file
 - File name === function export name